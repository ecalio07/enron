{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Fraud detection machine learning on Enron enteprise dataset\n",
    "\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "   1. Abstract\n",
    "   2. Workflow\n",
    "   3. Reprodutibility Environments and Fundamental Steps\n",
    "   4. Jupyter Notebook Structure\n",
    "   5. Methods and Procedures\n",
    "       1. Naive Bayes\n",
    "       2. SVM \n",
    "       3. Decision Tree\n",
    "   6. Summury of Result\n",
    "   7. References\n",
    "\n",
    "\n",
    "## 1. Abstract\n",
    "\n",
    "The purpose of this project is to study how well Naive Bayes, SVM, and Decision Tree machine learning algorithms can indentify emails by their authors. There will be comparinsons among them as to their respective performance and accuracy based on a pre-made list of email texts and the corresponding authors based on Enron dataset comprised of 146 users with 21 features each.\n",
    "\n",
    "The Enron scandal, publicized in October 2001, eventually led to the bankruptcy of the Enron Corporation, an American energy company based in Houston, Texas, and the de facto dissolution of Arthur Andersen, which was one of the five largest audit and accountancy partnerships in the world. In addition to being the largest bankruptcy reorganization in American history at that time, Enron was cited as the biggest audit failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "n_groups = 5\n",
    "\n",
    "means_men = (20, 35, 30, 35, 27)\n",
    "std_men = (2, 3, 4, 1, 2)\n",
    "\n",
    "means_women = (25, 32, 34, 20, 25)\n",
    "std_women = (3, 5, 2, 3, 3)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.35\n",
    "\n",
    "opacity = 0.4\n",
    "error_config = {'ecolor': '0.3'}\n",
    "\n",
    "rects1 = plt.bar(index, means_men, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='b',\n",
    "                 yerr=std_men,\n",
    "                 error_kw=error_config,\n",
    "                 label='Men')\n",
    "\n",
    "rects2 = plt.bar(index + bar_width, means_women, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='r',\n",
    "                 yerr=std_women,\n",
    "                 error_kw=error_config,\n",
    "                 label='Women')\n",
    "\n",
    "plt.xlabel('Group')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Scores by group and gender')\n",
    "plt.xticks(index + bar_width / 2, ('A', 'B', 'C', 'D', 'E'))\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Reprodutibility Environments and Fundamental Steps\n",
    "\n",
    "This project can be reproduced in two distinct manners: through section \"3.1. Jupyter Notebook Envonment and Procedures\" **OR**  section \"3.2. Docker Envonment and Procedures\". Both will contain the common/fundamental tools below, the difference is that in 3.1 (Jypyter Notebook Env.) you will have to install the fundamental tools manually, whereas in 3.2 (Jypyter Notebook Env.), you will need only docker client installed to run the docker file (xxx.docker) available in **environments folder**, because all required tools will come already installed in this file.\n",
    "\n",
    "* **Common/Fundamental Tools**: git version 2.7.4, anaconda 4.3.1 (64-bit), Jupyter Notebook Server 4.3.1, Python 2.7.13, scikit-learn library.\n",
    "\n",
    "### 3.1. Jupyter Notebook Envonment and Procedures\n",
    "\n",
    "* 3.1.1 Install Anaconda 4.3.1 for Python 2.7.13. Anaconda will automatically install Jupyter Notebook Server 4.3.1 and Python 2.7.13: https://www.continuum.io/downloads \n",
    "* 3.1.2 Install scikit-learn: http://scikit-learn.org/stable/developers/advanced_installation.html\n",
    "* 3.1.3 Install git version 2.7.4: https://git-scm.com/book/en/v2/Getting-Started-Installing-Git\n",
    "* 3.1.4 Clone files from this hosting to your desired path in your local machine by issuing the following command:<br>  **\"git clone https://github.com/ecalio07/enron-paper.git\"**\n",
    "* 3.1.5 Start Jupyter Server and create its structure just like the one in section 4 (Jupyter Notebook Structure). Start by creating folders and then upload the files cloned in previous step (3.1.4) to their respective directories.  \n",
    " \n",
    "### 3.2. Docker Envonment and Procedures\n",
    "\n",
    "* 3.2.1 Install Docker: https://www.docker.com/community-edition#/download / https://github.com/docker/labs/blob/master/beginner/chapters/setup.md\n",
    "* 3.2.1 Start Docker Image\n",
    "* 3.2.1 Start Jupyter Notebook Server. Verify that the notebook already comes with the correct folder and files structure(refer to section 4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.  Jupyter Notebook Structure\n",
    "\n",
    "Jupyter notebook server must have folders and files in the following structure. It should be the same structure as we have here in GitHub, except for the environments folder.\n",
    "\n",
    "<img src=\"structure.png\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Methods and Procedures\n",
    "\n",
    "It will be performed arguments confirguration according to each classifier below so as to reach best time performance and accurance, as well as comparisons of results.\n",
    "\n",
    "We have a set of emails, half of which were written by one person and the other half by another person at the same company . Our objective is to classify the emails as written by one person or the other based only on the text of the email. \n",
    "\n",
    "###   5.1. Naive Bayes\n",
    "   * make tests with percentile parameter\n",
    "###   5.2. SVM\n",
    "   * deploy an rbf kernel\n",
    "   * optimize C parameter    \n",
    "###   5.3. Decision Tree\n",
    "   * make tests with percentile parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Summury of Result\n",
    "We will reach to a conclusion based on pros and cons as to which classifier best suits to this scenario. Thus, we will have the oportunity explore these methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. References\n",
    " Main: https://classroom.udacity.com/courses/ud120"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
