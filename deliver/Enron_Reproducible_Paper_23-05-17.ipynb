{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Fraud detection machine learning on Enron enteprise dataset\n",
    "\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "   1. Abstract\n",
    "   2. Workflow\n",
    "   3. Reprodutibility Environments and Fundamental Steps\n",
    "   4. Jupyter Notebook Structure\n",
    "   5. Methods and Procedures\n",
    "       1. Naive Bayes\n",
    "       2. SVM \n",
    "       3. Decision Tree\n",
    "   6. Summury of Result\n",
    "   7. References\n",
    "\n",
    "\n",
    "## 1. Abstract\n",
    "\n",
    "The purpose of this project is to provide a reproducible paper regarding studies on how well Naive Bayes, SVM, and Decision Tree Machine Learning Algorithms can indentify emails by their authors using a pre-processed list of email texts and the corresponding authors based on the text dataset(comprised of 146 users with 21 features each) of the famous fraud scandal of the american bankrupt Enron Corporation. We will also study ways to work with parameters to improve accuracy and performance.\n",
    "\n",
    "NB: All contents and instructions used for this paper where based on the \"Udacity - Introduction to Machine Leaning course\", and were adaped according to the goals explained here. This is being used for educational pourposes only.\n",
    "\n",
    "\n",
    "For more information on the history of the coorporation, please verify the link below: <br>\n",
    "http://www.investopedia.com/updates/enron-scandal-summary/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Workflow\n",
    "\n",
    "<img src=\"../figures/workflow-a.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Reprodutibility Environments and Fundamental Steps\n",
    "\n",
    "This project can be reproduced in two distinct manners: through section \"3.1. Jupyter Notebook Envonment and Procedures\" **OR**  section \"3.2. Docker Envonment and Procedures\". Both will contain the common/fundamental tools below, the difference is that in 3.1 (Jypyter Notebook Env.) you will have to install the fundamental tools manually, whereas in 3.2 (Jypyter Notebook Env.), you will need only docker client installed to run the docker file (xxx.docker) available in **environments folder**, because all required tools will come already installed in this file.\n",
    "\n",
    "* **Common/Fundamental Tools**: git version 2.7.4, anaconda 4.3.1 (64-bit), Jupyter Notebook Server 4.3.1, Python 2.7.13, scikit-learn library.\n",
    "\n",
    "### 3.1. Jupyter Notebook Envonment and Procedures\n",
    "\n",
    "* 3.1.1 Install Anaconda 4.3.1 for Python 2.7.13. Anaconda will automatically install Jupyter Notebook Server 4.3.1 and Python 2.7.13: https://www.continuum.io/downloads \n",
    "* 3.1.2 Install scikit-learn: http://scikit-learn.org/stable/developers/advanced_installation.html or http://scikit-learn.org/stable/install.html\n",
    "* 3.1.3 Install git version 2.7.4: https://git-scm.com/book/en/v2/Getting-Started-Installing-Git\n",
    "* 3.1.4 Clone files from this hosting to your desired path in your local machine by issuing the following command:<br>  **\"git clone https://github.com/ecalio07/enron-paper.git\"**\n",
    "* 3.1.5 Start Jupyter Server and create its structure just like the one in section 4 (Jupyter Notebook Structure). Start by creating folders and then upload the files cloned in previous step (3.1.4) to their respective directories.  \n",
    " \n",
    "### 3.2. Docker Envonment and Procedures\n",
    "\n",
    "Docker environment can be reproduced on Ubuntu 16.04 64bits:\n",
    "\n",
    "* Find instruction clicking in the url: https://github.com/ecalio07/enron-paper/blob/master/deliver/README.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.  Jupyter Notebook Structure\n",
    "\n",
    "Jupyter notebook server must have folders and files in the following structure. It should be the same structure as we have here in GitHub, except for the environments folder.\n",
    "\n",
    "<img src=\"../figures/structure.png\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Methods and Procedures\n",
    "\n",
    "It will be performed arguments confirguration according to each classifier below so as to reach best time performance and accurance, as well as comparisons of results.\n",
    "\n",
    "We have a set of emails, half of which were written by one person and the other half by another person at the same company . Our objective is to classify the emails as written by one person or the other based only on the text of the email.\n",
    "\n",
    "In order to know which algorithm is best for this situation, we should make tests and by the results determine which one is most suitable for our scenario.\n",
    "\n",
    "A couple of years ago, J.K. Rowling (of Harry Potter fame) tried something interesting. She wrote a book, “The Cuckoo’s Calling,” under the name Robert Galbraith. The book received some good reviews, but no one paid much attention to it--until an anonymous tipster on Twitter said it was J.K. Rowling. The London Sunday Times enlisted two experts to compare the linguistic patterns of “Cuckoo” to Rowling’s “The Casual Vacancy,” as well as to books by several other authors. After the results of their analysis pointed strongly toward Rowling as the author, the Times directly asked the publisher if they were the same person, and the publisher confirmed. The book exploded in popularity overnight.\n",
    "\n",
    "We’ll do something very similar in this project. We have a set of emails, half of which were written by one person and the other half by another person at the same company . Our objective is to classify the emails as written by one person or the other based only on the text of the email. We will start with Naive Bayes in this mini-project, and then expand in later projects to other algorithms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "###   5.1. Naive Bayes\n",
    "\n",
    "It is consider the holy grail of probrabilist inference. It is based on Revend Thomas Bayes who used this principles (Bayes Rules) to infer the existence of God. He created a family of methods who influenced artificial inteligence and statistics. It uses in its algorithm the concepts of sensitivity and specitivity.\n",
    "\n",
    "Naive Bayes is a supervised classification algorithm used substancially in learning from documents (text learning). Each word is considered a feature and user names are considered the labes. It is called Naive because it ignores the words order.\n",
    "\n",
    "\n",
    "The classifier uses Posterior Probability, giving the rank occurance provided text. In order words, it will be trained with frequent texts(features) used by Chris and Sarah(labels), and it will calculate the probabily and determine if each test email is from Chris or Sara."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of Chris training emails: 7936\n",
      "no. of Sara training emails: 7884\n",
      "performance and accuracy being processed, please wait...\n",
      "training time:  0.838 s\n",
      "predicting time:  0.15 s\n",
      "0.973265073948\n"
     ]
    }
   ],
   "source": [
    "#NAIVE BAYES\n",
    "\n",
    "import sys\n",
    "from time import time\n",
    "sys.path.append(\"../tools\")\n",
    "from email_preprocess import preprocess\n",
    "\n",
    "\n",
    "### features_train and features_test are the features for the training\n",
    "### and testing datasets, respectively\n",
    "### labels_train and labels_test are the corresponding item labels\n",
    "features_train, features_test, labels_train, labels_test = preprocess()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################################################\n",
    "### your code goes here ###\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = GaussianNB()\n",
    "t0 = time()\n",
    "clf.fit(features_train, labels_train)\n",
    "print \"training time: \", round(time()-t0, 3), \"s\"\n",
    "\n",
    "t1 = time()\n",
    "pred = clf.predict(features_test)\n",
    "print \"predicting time: \", round(time()-t1, 3), \"s\"\n",
    "\n",
    "accuracy = accuracy_score(labels_test, pred)\n",
    "\n",
    "print accuracy\n",
    "\n",
    "\n",
    "\n",
    "## IT IS PENDING ADDING CODE TO DISPLAY HOW MANY EMAILS WERE PREDICTED TO BE CHRIS AND SARA, \n",
    "## WWHAT EMAILS WENT TO CHRIS AND SARA\n",
    "## DISPLAY GRAPHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   5.2. SVM\n",
    "\n",
    "It separate two classes creating a line separator(decision boundary), handling well margims and outliers. \n",
    "\n",
    "**For information on Parameters, Advantages and Disadvantages:** http://scikit-learn.org/stable/modules/svm.html\n",
    "\n",
    "For this experiment we will work on changing values for paremeter the parameters **C**, **kernel** and **gamma**. when initiating SVC function. It can be a simple choice with few parameter (ex 1), multiple paramenter (ex 2) or no parameters at all.\n",
    "\n",
    "* **ex 1** <br>\n",
    "linear_kernel_svm = svm.SVC(kernel='rbf', C=10000.)\n",
    "\n",
    "* **ex 2** <br>\n",
    "linear_kernel_svm = svm.SVC(**C=1.0**, **kernel**='rbf', degree=3, **gamma='auto'**, coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape=None, random_state=None)[source]\n",
    "\n",
    "In machine learning we should avoid OVERFITTING. Because of that, we wil tune the parameters below since all of them affect overfitting and results like accuracy, performance.\n",
    "\n",
    "**C:** controls the tradeoff between smooth decision boundary and classification training points correctly. In theory, a large value of C means that you will get more training points correctly.\n",
    "\n",
    "**gamma:** defines how far a the influence of a single training example reaches. If gamma has a low value, every point has a far reach. If gamma has a high value, each training example has a close reach. High value might make the decision boundary less linear, for it will be closer to training points.\n",
    "\n",
    "**kernel** parameter can be ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’ or a callable. If none is given, ‘rbf’ will be used.\n",
    "\n",
    "**Please refer to the following url for more information on Parameters:** <br>\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC\n",
    "\n",
    "\n",
    "### Steps to reproduce focusing on Accuracy vs Performance\n",
    "\n",
    "In this testing we will improve the accuracy at the cost of performance.\n",
    "\n",
    "* 1 - Run the code as it is and record the results\n",
    "* 2 - Comment the two lines below the comment section \"REDUCING DATASET\" and record the result.\n",
    "* 3 - Compare the two results and notice that accurace is better in step 2. However, it took much longer to run because data set is larger. We can then conclude the with larger datasets we get much better accuracy but that will certainly affect training and testing performance.\n",
    "* 4 - Uncomment the two lines performed in step 2. Leaving the code as it was before step 2. \n",
    "\n",
    "\n",
    "### Steps to reproduce focusing on Gamma parameter\n",
    "\n",
    "* 1 - Uncomment the code (gamma with HIGH value) \"linear_kernel_svm = svm.SVC(kernel='rbf', gamma=1.0)\"; comment the others instatiators and check results. ?????? Compare linear graph????????\n",
    "* 2 - Uncomment the code (gamma with LOW value) \"linear_kernel_svm = svm.SVC(kernel='rbf', gamma=1.0)\"; comment the others instatiators and check results. \n",
    "\n",
    "### Steps to reproduce focusing on Kernel parameter\n",
    "\n",
    "* 1 - Run the code as it is and record the results\n",
    "* 2 - Change the kernel of your SVM to “rbf” and record the result.\n",
    "* 3 - Compare the two results and notice that accurace is better with this more complex kernel.\n",
    "* 4 - Keep this kernel (rbf) for the next tests.\n",
    "\n",
    "\n",
    "### Steps to reproduce focusing on C parameter\n",
    "\n",
    "* 1 - Uncomment the code below the section \"LINES OF CODE MEANT TO TEST C PARAMETER\" and comment the other related to other parameters\n",
    "* 2 - Try several values of C (say, 10.0, 100., 1000., and 10000.) and record all results\n",
    "* 3 - Compare the results and notice that the higher is the value of C, the better is accuray.\n",
    "* 4 - Recorde the best accurcy result of C and notice that we are still using 1% of the dataset.\n",
    "* 5 - Coment the 2 lines below the section REDUCING DATASET TO 1% and run the code again. Be patient because processing will be slow now.\n",
    "* 6 - Compare accuracy result with the one recorded in step 4. Verify that accuray must be hight in a larger dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eduardo/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of Chris training emails: 7936\n",
      "no. of Sara training emails: 7884\n",
      "performance and accuracy being processed, please wait...\n",
      "training time with SVM's linear kernel 100.790041208\n",
      "prediction time with SVM's linear kernel 10.3493950367\n",
      "0.990898748578\n"
     ]
    }
   ],
   "source": [
    "#SVM TEST\n",
    "\n",
    "import sys\n",
    "from time import time\n",
    "sys.path.append(\"../tools\")\n",
    "from email_preprocess import preprocess\n",
    "\n",
    "\n",
    "### features_train and features_test are the features for the training\n",
    "### and testing datasets, respectively\n",
    "### labels_train and labels_test are the corresponding item labels\n",
    "features_train, features_test, labels_train, labels_test = preprocess()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################################################\n",
    "### your code goes here ###\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#####TEST CHANING PARAMETERS\n",
    "######################## JUST ONE LINE IN HERE MUST BE UNCOMMENTED ######################## \n",
    "\n",
    "### LINES OF CODE MEANT TO TEST GAMMA PARAMETER\n",
    "#linear_kernel_svm = svm.SVC(kernel='rbf', gamma=1000) #GAMMA WITH HIGH VALUE\n",
    "#linear_kernel_svm = svm.SVC(kernel='rbf', gamma=1.0) #GAMMA WITH LOW VALUE\n",
    "\n",
    "### LINES OF CODE MEANT TO TEST C PARAMETER\n",
    "linear_kernel_svm = svm.SVC(kernel='rbf', C=10000.0)\n",
    "\n",
    "\n",
    "\n",
    "######################## REDUCING DATASET TO 1% ########################\n",
    "features_train = features_train[:len(features_train)/100]\n",
    "labels_train = labels_train[:len(labels_train)/100]\n",
    "####### END ############\n",
    "\n",
    "t0 = time()\n",
    "linear_kernel_svm.fit(features_train, labels_train)\n",
    "print \"training time with SVM's linear kernel\", time() - t0\n",
    "\n",
    "t1 = time()\n",
    "pred = linear_kernel_svm.predict(features_test)\n",
    "print \"prediction time with SVM's linear kernel\", time() - t1\n",
    "\n",
    "print \"accuracy being processed, please wait...\"\n",
    "acc = accuracy_score(labels_test, pred)\n",
    "print acc\n",
    "\n",
    "#########################################################\n",
    "\n",
    "def time_with_power(power, people,times):\n",
    "    results = nd.random.power(power, people)\n",
    "    for i in range(times):\n",
    "            results += nd.random.power(power, 1000)\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "## IT IS PENDING ADDING CODE TO DISPLAY HOW MANY EMAILS WERE PREDICTED TO BE CHRIS AND SARA, \n",
    "## WWHAT EMAILS WENT TO CHRIS AND SARA\n",
    "## DISPLAY GRAPHS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   5.3. Decision Tree\n",
    "   * make tests with percentile parameter\n",
    "   \n",
    "   \n",
    "   **Advantages and Disadvantages:** http://scikit-learn.org/stable/modules/tree.html <br>\n",
    "   **Parameters Information:** http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n",
    "   \n",
    "   Main parameters covered in this experiment will be:\n",
    "   * min_samples_split: it controls how deep the tree will reach\n",
    "   * percentile: \n",
    "   \n",
    "\n",
    "### Steps to reproduce focusing on \"min_samples_split\" parameter\n",
    "\n",
    "* 1 - Run the code as it is and record the results\n",
    "* 2 - Change the min_samples_split parameter to 40 and record results.\n",
    "* 3 - Compare the two results and notice that accurace is better with this more complex kernel.\n",
    "* 4 - Keep this kernel (rbf) for the next tests.\n",
    "\n",
    "### Steps to reproduce focusing on \"percentile\" parameter\n",
    "\n",
    "* 1 - Run the code as it is and record the number of features\n",
    "* 2 - Go into ../tools/email_preprocess.py, and find the line of code that looks like this:selector = SelectPercentile(f_classif, percentile=10). Change percentile from 10 to 1, and rerun dt_author_id.py. Record the number of features.\n",
    "* 3 - Compare the number of features\n",
    "* 4 - Check accuracy when you use 1% of your available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of Chris training emails: 7936\n",
      "no. of Sara training emails: 7884\n",
      "performance and accuracy being processed, please wait...\n",
      "Size of features matrix:  (15820, 3785)\n",
      "accuracy being processed, please wait...\n",
      "Accuracy:  0.978384527873\n"
     ]
    }
   ],
   "source": [
    "#DECISION TREE\n",
    "\n",
    "import sys\n",
    "from time import time\n",
    "sys.path.append(\"../tools\")\n",
    "from email_preprocess import preprocess\n",
    "\n",
    "\n",
    "### features_train and features_test are the features for the training\n",
    "### and testing datasets, respectively\n",
    "### labels_train and labels_test are the corresponding item labels\n",
    "features_train, features_test, labels_train, labels_test = preprocess()\n",
    "\n",
    "print \"Size of features matrix: \", features_train.shape\n",
    "\n",
    "\n",
    "#########################################################\n",
    "### your code goes here ###\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(min_samples_split=40)\n",
    "\n",
    "clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "\n",
    "print \"accuracy being processed, please wait...\"\n",
    "acc = accuracy_score(labels_test, pred)\n",
    "print \"Accuracy: \", acc\n",
    "#########################################################\n",
    "\n",
    "\n",
    "## IT IS PENDING ADDING CODE TO DISPLAY HOW MANY EMAILS WERE PREDICTED TO BE CHRIS AND SARA, \n",
    "## WWHAT EMAILS WENT TO CHRIS AND SARA\n",
    "## DISPLAY GRAPHS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Summury of Result\n",
    "\n",
    "**Naive Bayes** is really easy to implement and efficient. The relative simplicity of the algorithm and the independent features assumption of Naive Bayes make it a strong performer for classifying texts. It is good when working with a lot of noise of the data. On the other hand, it can break for some phrases for considering the words individually.\n",
    "\n",
    "**SVM** works very well in complicated domains with clear margin of separation but it doesn't perform well in very large datasets, for it can become slow and prone to overfitting. As for tunning we can conclude that best accuracy were achieved with  parameters RBF kernel, C=10000, and full dataset. As for performance, there will always be a tradeoff with accuracy reducing the dataset to make the code faster.\n",
    "\n",
    "**Decision Trees** are easy to use but are prone to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. References\n",
    " Main: https://classroom.udacity.com/courses/ud120"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
